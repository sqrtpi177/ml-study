{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY5hBlYgPCHU"
   },
   "source": [
    "DCGAN 성공한 버전. MNIST 데이터에 맞춰 공식 튜토리얼 약간 바꿨습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWnllVZmp9Sk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\solar\\anaconda3\\envs\\torch\\lib\\site-packages (1.5.1)\n",
      "Random Seed:  999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28d59395eb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "# manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7xrrgzBMS_R"
   },
   "outputs": [],
   "source": [
    "dataroot = './data/mnist'\n",
    "workers = 2\n",
    "ngpu = 1\n",
    "batch_size = 128\n",
    "\n",
    "image_size = 64\n",
    "nc = 1\n",
    "nz = 100\n",
    "ngf = 256\n",
    "ndf = 256\n",
    "\n",
    "num_epochs = 200\n",
    "lr = 0.0002\n",
    "beta1 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLsr_juePpGX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n"
     ]
    }
   ],
   "source": [
    "# dataset = dset.ImageFolder(root=dataroot,\n",
    "#                            transform=transforms.Compose([\n",
    "#                                transforms.Resize(image_size),\n",
    "#                                transforms.CenterCrop(image_size),\n",
    "#                                transforms.ToTensor(),\n",
    "#                                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "#                            ]))\n",
    "\n",
    "# dataloader = torch.utils.data.Dataloader(dataset,\n",
    "#                                          batch_size=batch_size,\n",
    "#                                          shuffle=True,\n",
    "#                                          num_workers=workers)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "dataset = dset.MNIST(root=dataroot,\n",
    "                     train=True,\n",
    "                     transform=transform,\n",
    "                     download=True\n",
    "                     )\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=workers)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() and ngpu > 0 else \"cpu\")\n",
    "\n",
    "print(len(dataloader))\n",
    "\n",
    "# real_batch = next(iter(dataloader))\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.axis(\"off\")\n",
    "# plt.title(\"Training Images\")\n",
    "# plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64],\n",
    "#                                          padding=2,\n",
    "#                                          normalize=True).cpu(),\n",
    "#                                          (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRoJbAx5APMo"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ruztCn-TyVK"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(  # nz\n",
    "            nn.ConvTranspose2d(nz, ngf*4, 4, 1, 0, bias=False),  # ngf*4@4*4\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 3, 2, 1, bias=False),  # ngf*2@7*7\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),  # ngf@14*14\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),  # nc@28*28\n",
    "            nn.Tanh()  # [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPlJCz85V7OQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ConvTranspose2d(1024, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ConvTranspose2d(256, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (10): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "if device.type == \"cuda\" and ngpu > 1:\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "netG.apply(weights_init)\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ot59GUB1WmiQ"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(  # nc@28*28\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),  # ndf@14*14\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),  # ndf*2@7*7\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*2, 1, 4, 1, 0, bias=False),  # 1@4*4\n",
    "            nn.Flatten(1, -1),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1scx7IcW_sV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(1, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (6): Flatten()\n",
      "    (7): Linear(in_features=16, out_features=1, bias=True)\n",
      "    (8): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "if device.type == \"cuda\" and ngpu > 1:\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "netD.apply(weights_init)\n",
    "\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T_VT9RVkKtBO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "   ConvTranspose2d-1           [-1, 1024, 4, 4]       1,638,400\n",
      "       BatchNorm2d-2           [-1, 1024, 4, 4]           2,048\n",
      "              ReLU-3           [-1, 1024, 4, 4]               0\n",
      "   ConvTranspose2d-4            [-1, 512, 7, 7]       4,718,592\n",
      "       BatchNorm2d-5            [-1, 512, 7, 7]           1,024\n",
      "              ReLU-6            [-1, 512, 7, 7]               0\n",
      "   ConvTranspose2d-7          [-1, 256, 14, 14]       2,097,152\n",
      "       BatchNorm2d-8          [-1, 256, 14, 14]             512\n",
      "              ReLU-9          [-1, 256, 14, 14]               0\n",
      "  ConvTranspose2d-10            [-1, 1, 28, 28]           4,096\n",
      "             Tanh-11            [-1, 1, 28, 28]               0\n",
      "================================================================\n",
      "Total params: 8,461,824\n",
      "Trainable params: 8,461,824\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 2.11\n",
      "Params size (MB): 32.28\n",
      "Estimated Total Size (MB): 34.39\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 14, 14]           4,096\n",
      "         LeakyReLU-2          [-1, 256, 14, 14]               0\n",
      "            Conv2d-3            [-1, 512, 7, 7]       2,097,152\n",
      "       BatchNorm2d-4            [-1, 512, 7, 7]           1,024\n",
      "         LeakyReLU-5            [-1, 512, 7, 7]               0\n",
      "            Conv2d-6              [-1, 1, 4, 4]           8,192\n",
      "           Flatten-7                   [-1, 16]               0\n",
      "            Linear-8                    [-1, 1]              17\n",
      "           Sigmoid-9                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 2,110,481\n",
      "Trainable params: 2,110,481\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.34\n",
      "Params size (MB): 8.05\n",
      "Estimated Total Size (MB): 9.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(netG, (100, 1, 1))\n",
    "summary(netD, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "poDda0XTdz4C"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "g_optimizer = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrVhheC3tBKR"
   },
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    out = (x+1)/2\n",
    "    return out\n",
    "\n",
    "def reset_grad():\n",
    "    d_optimizer.zero_grad()\n",
    "    g_optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUfUdusSBgFf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\nException raised from createCublasHandle at ..\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:8 (most recent call first):\n00007FFF176175A200007FFF17617540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFEA5F9AEA800007FFEA5F99E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9A7D800007FFEA5F99E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9B66700007FFEA5F9B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9B24700007FFEA5F9B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9320700007FFEA5F924B0 torch_cuda.dll!at::native::sparse_mask_cuda [<unknown file> @ <unknown line number>]\n00007FFEA549CA9700007FFEA549B990 torch_cuda.dll!at::native::lerp_cuda_tensor_out [<unknown file> @ <unknown line number>]\n00007FFEA549E4D200007FFEA549DF60 torch_cuda.dll!at::native::addmm_out_cuda [<unknown file> @ <unknown line number>]\n00007FFEA549F64300007FFEA549F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFEA6001B0F00007FFEA5F9E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFEA5FF1B2200007FFEA5F9E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFE9E0BD94900007FFE9E0B8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFE9E0F057700007FFE9E0F0520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFE9F44EC7900007FFE9F35E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFE9DC0715700007FFE9DC06290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFE9E0BD94900007FFE9E0B8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFE9E1D210700007FFE9E1D20B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFE9F2EB71100007FFE9F2EA760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFE9F2A16D800007FFE9F2A1580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFE9F297E9100007FFE9F297B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFE9F7FF9BA00007FFE9F7FF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFE9F8003AD00007FFE9F7FFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFE9F804FE200007FFE9F804CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFE9F804C4100007FFE9F804BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFE68690A7700007FFE6866A150 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFE9F7FBF1400007FFE9F7FB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFF6CE7154200007FFF6CE714B0 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFF6EDE6FD400007FFF6EDE6FC0 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFF6F0BCEC100007FFF6F0BCEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3f0b50ed8908>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mreset_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0md_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0md_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_ALLOC_FAILED when calling `cublasCreate(handle)`\nException raised from createCublasHandle at ..\\aten\\src\\ATen\\cuda\\CublasHandlePool.cpp:8 (most recent call first):\n00007FFF176175A200007FFF17617540 c10.dll!c10::Error::Error [<unknown file> @ <unknown line number>]\n00007FFEA5F9AEA800007FFEA5F99E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9A7D800007FFEA5F99E70 torch_cuda.dll!at::cuda::getCurrentCUDASparseHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9B66700007FFEA5F9B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9B24700007FFEA5F9B1A0 torch_cuda.dll!at::cuda::getCurrentCUDABlasHandle [<unknown file> @ <unknown line number>]\n00007FFEA5F9320700007FFEA5F924B0 torch_cuda.dll!at::native::sparse_mask_cuda [<unknown file> @ <unknown line number>]\n00007FFEA549CA9700007FFEA549B990 torch_cuda.dll!at::native::lerp_cuda_tensor_out [<unknown file> @ <unknown line number>]\n00007FFEA549E4D200007FFEA549DF60 torch_cuda.dll!at::native::addmm_out_cuda [<unknown file> @ <unknown line number>]\n00007FFEA549F64300007FFEA549F560 torch_cuda.dll!at::native::mm_cuda [<unknown file> @ <unknown line number>]\n00007FFEA6001B0F00007FFEA5F9E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFEA5FF1B2200007FFEA5F9E0A0 torch_cuda.dll!at::native::set_storage_cuda_ [<unknown file> @ <unknown line number>]\n00007FFE9E0BD94900007FFE9E0B8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFE9E0F057700007FFE9E0F0520 torch_cpu.dll!at::mm [<unknown file> @ <unknown line number>]\n00007FFE9F44EC7900007FFE9F35E010 torch_cpu.dll!torch::autograd::GraphRoot::apply [<unknown file> @ <unknown line number>]\n00007FFE9DC0715700007FFE9DC06290 torch_cpu.dll!at::indexing::TensorIndex::boolean [<unknown file> @ <unknown line number>]\n00007FFE9E0BD94900007FFE9E0B8FA0 torch_cpu.dll!at::bucketize_out [<unknown file> @ <unknown line number>]\n00007FFE9E1D210700007FFE9E1D20B0 torch_cpu.dll!at::Tensor::mm [<unknown file> @ <unknown line number>]\n00007FFE9F2EB71100007FFE9F2EA760 torch_cpu.dll!torch::autograd::profiler::Event::kind [<unknown file> @ <unknown line number>]\n00007FFE9F2A16D800007FFE9F2A1580 torch_cpu.dll!torch::autograd::generated::AddmmBackward::apply [<unknown file> @ <unknown line number>]\n00007FFE9F297E9100007FFE9F297B50 torch_cpu.dll!torch::autograd::Node::operator() [<unknown file> @ <unknown line number>]\n00007FFE9F7FF9BA00007FFE9F7FF300 torch_cpu.dll!torch::autograd::Engine::add_thread_pool_task [<unknown file> @ <unknown line number>]\n00007FFE9F8003AD00007FFE9F7FFFD0 torch_cpu.dll!torch::autograd::Engine::evaluate_function [<unknown file> @ <unknown line number>]\n00007FFE9F804FE200007FFE9F804CA0 torch_cpu.dll!torch::autograd::Engine::thread_main [<unknown file> @ <unknown line number>]\n00007FFE9F804C4100007FFE9F804BC0 torch_cpu.dll!torch::autograd::Engine::thread_init [<unknown file> @ <unknown line number>]\n00007FFE68690A7700007FFE6866A150 torch_python.dll!THPShortStorage_New [<unknown file> @ <unknown line number>]\n00007FFE9F7FBF1400007FFE9F7FB780 torch_cpu.dll!torch::autograd::Engine::get_base_engine [<unknown file> @ <unknown line number>]\n00007FFF6CE7154200007FFF6CE714B0 ucrtbase.dll!configthreadlocale [<unknown file> @ <unknown line number>]\n00007FFF6EDE6FD400007FFF6EDE6FC0 KERNEL32.DLL!BaseThreadInitThunk [<unknown file> @ <unknown line number>]\n00007FFF6F0BCEC100007FFF6F0BCEA0 ntdll.dll!RtlUserThreadStart [<unknown file> @ <unknown line number>]\n"
     ]
    }
   ],
   "source": [
    "img_list = []\n",
    "g_losses = []\n",
    "d_losses = []\n",
    "total_step = len(dataloader)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(dataloader, 0):\n",
    "        \"\"\"# train D\n",
    "        # train with real images\n",
    "        netD.zero_grad()\n",
    "        real_cpu = data[0].to(device)\n",
    "        print(real_cpu.shape)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.bool, device=device)\n",
    "        output = netD(real_cpu).view(-1)\n",
    "\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake images\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        errD_fake = criterion(output, label)\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\"\"\"\n",
    "\n",
    "        # train netD\n",
    "        print(type(images))\n",
    "        images = images.to(device)\n",
    "\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        outputs = netD(images)\n",
    "        d_loss_real = criterion(outputs, real_labels[:len(outputs)])\n",
    "        real_score = outputs\n",
    "\n",
    "        z = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "        fake_images = netG(z)\n",
    "        outputs = netD(fake_images)\n",
    "        d_loss_fake = criterion(outputs, fake_labels[:len(outputs)])\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        reset_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "\n",
    "        \"\"\"# train G\n",
    "        netG.zero_grad()\n",
    "        label.fill(real_label)\n",
    "        output = netD(fake).view(-1)\n",
    "\n",
    "        errG = criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        optimizerG.step()\"\"\"\n",
    "\n",
    "        # train netG\n",
    "        z = torch.randn(batch_size, nz, 1, 1).to(device)\n",
    "        fake_images = netG(z)\n",
    "        outputs = netD(fake_images)\n",
    "\n",
    "        g_loss = criterion(outputs, real_labels[:len(outputs)])\n",
    "        reset_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "\n",
    "        \"\"\"# output training stats\n",
    "        if i%200 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tloss_D: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "            % (epoch+1, num_epochs, i, len(dataloader),\n",
    "               errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        if iters%500 == 0 or (epoch+1==num_epochs and i+1==len(dataloader)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "        iters += 1\"\"\"\n",
    "\n",
    "        # output training data\n",
    "        if (i+1)%200 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                  .format(epoch+1, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                          real_score.mean().item(), fake_score.mean().item()))\n",
    "        \n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "    \n",
    "    if not os.path.exists('./gan-02-images'):\n",
    "        os.makedirs('./gan-02-images')\n",
    "\n",
    "    if (epoch+1) == 1:\n",
    "        vutils.save_image(denorm(images), './gan-02-images/real_images.png')\n",
    "    \n",
    "    vutils.save_image(denorm(fake_images), './gan-02-images/fake_images-{}.png'.format(epoch+1))\n",
    "    img_list.append(vutils.make_grid(fake_images, padding=2, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLIKTgz6B8I_"
   },
   "outputs": [],
   "source": [
    "torch.save(netG.state_dict(), 'G.ckpt')\n",
    "torch.save(netD.state_dict(), 'D.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "siGnLm3mFdtg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO1vp4jXTkjr21sqR+FQ4vN",
   "collapsed_sections": [],
   "mount_file_id": "1W-AXLSTN5DVkFcYJ_XNcGY4hmcsCZKLX",
   "name": "practice-gan-02.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
